# [Leveraging Pre-trained Knowledge from 2D Foundation Model for 3D Question Answering]()

This repo contains the code for "Leveraging Pre-trained Knowledge from 2D Foundation Model for 3D Question Answering". 

## Install
Please create an env for this project using anaconda:  
```
>conda create -n 3dqa python==3.8.13
>conda activate 3dqa
>pip install -r requirements.txt 
```

Then, you should compile the CUDA accelerated PointNet++: 
```
cd ./networks/detr_3d/third_party/pointnet2
python setup.py install
```

## Data Preparation
For 3D scenes and QA data, please follow the instructions from [SQA3D](https://github.com/SilongYong/SQA3D). Then, please specify the paths in `DataLoader.py`. Their meanings are as follows: 
```
sampled_frame_path: results of sampled frames
blip2_feat_path: features of frames that are extracted by BLIP2
qa_data_path: path to SQA3D data
ans_dict_path: answer set of SQA3D
pc_path: path to point clouds
``` 

You can find the answer set of SQA3D [here](), which is generated by us from the SQA3D data. And please note that `pc_path` should look like `<path_to_pc>/<scene_id>_aligned_vert.npy"`. 

For features and sampled frames, you can find them [here](). You can also follow the [instructions](https://github.com/salesforce/LAVIS) of BLIP2, for [image-text-matching](https://github.com/salesforce/LAVIS/blob/main/examples/blip2_image_text_matching.ipynb) and [feature extraction](https://github.com/salesforce/LAVIS/blob/main/examples/blip2_feature_extraction.ipynb) respectively. 

## Usage
Once the data and feature is ready, you can easily run the code. You can train the model by running: 
```
python train.py -v=train -detector_weights=<path_to_detector_weights>
```
It will train the model and save to ['./models']. You can find our best checkpoint [here](), and pretrained detector [here](). 
